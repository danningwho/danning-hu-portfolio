| [home page](https://danningwho.github.io/danning-hu-portfolio/) | [data viz examples](https://danningwho.github.io/danning-hu-portfolio/dataviz-examples) | [critique by design](https://danningwho.github.io/danning-hu-portfolio/critique-by-design) | [final project I](https://danningwho.github.io/danning-hu-portfolio/final-project-part-one) | [final project II](https://danningwho.github.io/danning-hu-portfolio/final-project-part-two) | [final project III](https://danningwho.github.io/danning-hu-portfolio/final-project-part-three) |

# The final data story
Link to final data story: [here](https://preview.shorthand.com/mSFMAwrZ5f9Jykoa) 
(Shorthand did not allow me to publish the final)

# Changes made since Part II + Final Design Decisions
1. Given the feedback regarding real names/potential doxing in the facebook post example of misinformation, I removed it and instead replaced it with the PolitiFact fact check screenshot + link. This one does not have any names or images of who posted the original post.
2. I double checked image attributions as well to make sure it was in line with Emily from CMU library's advice.
3. Bolstered content in "The Rise of Generative AI" by adding small section on identifying AI images. I decided not to put it in the call to action section as I want to maintain the spotlight on "think twice before you share."
4. Changed the title of the covid-19 discinformation chart to "While Correlation â‰  Causation, Disinformation COVID-19 Publications in 2020 Coincide with General Upticks in New Cases" from "Disinformation Publications in 2020" fo more clarity. I also changed the Y-Axis title to clearly indicate that it is the quanity of disinformation publications. Finally, I changed the line color to red to maintain consistency with other charts on the page. Ideally, this makes the project as a whole more cohesive with the main colors being dark blue, light blue, white, black, and red.


## The audience
When I first started this project, my audience was set at "general public" as I thought it was information most should be cognizant of. From feedback, one criticism I got from phase 1 was to think about narrowing the scope and better defining who I want my audience should be. This leads to my final audience: younger Americans (18-29).

**Why younger Americans?**
Some key reasons why I looked towards the younger demographic is that I have the greatest amount of access in user interviews to people of this age group and the high percentage of social media usage (as a news source). It is easy to assume that since most people from this demographic grew up with and around techonology and social media in its current form, they are least succeptible to misinformation/gen AI creation's deception. From said user interviews, I got great insight on the varying levels of knowledge of mis/disinformation + AI capabilities. Those who have more interest or have their finger on the pulse on current events are more likely to be aware. However, it is crucial to fold in readers/viewers such that they are equipped with similar levels of knowledge when presented with the argument and call to action.
* I added more examples of misinformation as a direct response to feedback from phase 2 interviews: 2 examples of 2016 mis/disinformation and 2 COVID-19 related examples.
* I added the PEW Research Center statistics at the start of the page to anchor the audience + asking where the reader got their news from.


## References
*References listed in Shorthand*

## AI acknowledgements
> I used AI to generate a fake food recall press release as an example in the project: "this is a fictional scenario I am creating for a project on misinformation. Can you write me a eye catching news article headline with an author called "Melanie Simora" that works at WTAC. The subject should be about a food recall on butter. You can decide what the reason behind the recall is"
> [https://chatgpt.com/share/...](https://chatgpt.com/share/67b6bb08-6c04-8000-83db-4ad570c3276a)



# Final thoughts

There is so much content/information on misinformation it is hard to keep everything contained to a reasonable timeframe (for the presentation) and scope (for the project as a whole). Generative AI in misinformation/disinformation is still relatively new in the sense that its popularity only boomeed in around ~2020 making finding comprehensive data difficult. I would love to explore more on the impact on Generative AI on how believable misinformation has become with it but something like that seems hard to measure.

I was most excited to construct a story/narative. Keeping the story beats relatively simple/focused on a particular topic made it easier in my head to organize and structure what content or data goes where. For example, I added a section describing some tips/tricks to identifying AI generated content. That information is applicable to both the Gen AI section also the last "call to action" section. I opted to keep it contained in the former section as I wanted a clear focus at the end to be on a single message. Additionally, it just seemed to fit well in the gen ai + misinfo section as I had a part asking readers to take a quiz on distinguishing real vs. ai generated images.

As for the final message itself, I wanted to keep it feasible and actionable for an individual. It is easy to throw your hands up and not change any of your behavior when the perceived problem is too big for a single person to handle. I hope that I conveyed a relatively hopeful action item that is tangible for most.
